{"version":"1","records":[{"hierarchy":{"lvl1":"About me"},"type":"lvl1","url":"/about","position":0},{"hierarchy":{"lvl1":"About me"},"content":"I’m a physicist turned software engineer.\n\nI work on projects that make it easier to analyse and share massive scientific datasets. I strongly feel that progress in most fields of computational science, including crucially Climate Science, are bottlenecked by how uneccessarily hard that is to do right now.","type":"content","url":"/about","position":1},{"hierarchy":{"lvl1":"About me","lvl2":"What I do"},"type":"lvl2","url":"/about#what-i-do","position":2},{"hierarchy":{"lvl1":"About me","lvl2":"What I do"},"content":"Open Source Software and Communities for Science\n\nI contribute to a number of open-source software projects that support this aim, often as part of the \n\nPangeo Community.\n\nA few projects I’m particularly proud of or excited about, and my role in them:\n\nXarray - N-D labeled arrays and datasets in Python (core maintainer).\n\nVirtualiZarr - Cloud-Optimizes your Scientific Data as Virtual Zarr stores, using Xarray syntax (original author and lead developer).\n\nCubed - Scalable array processing with bounded memory (cheerleader, and author of the \n\nCubed-Xarray integration).\n\nFROST - Federated registry of all scientific datasets (originator - I’m trying to make this a thing).\n\nCheck out my \n\nmy GitHub page for more details.\n\nScientific Research Dilettante\n\nI have been involved with research projects in various fields, including:\n\nNuclear Fusion Plasma Physics\n\nPhysical Oceanography\n\nOcean-based Carbon Dioxide Removal\n\nHypersonic Aerothermodynamics\n\nSuperconductivity\n\nIn every field I have felt the same kinds of pain around doing computational work, which motivates my software projects.\n\nFor a list of publications and scholarly artifacts in which I’ve been involved,\ncheck out \n\nmy ORCID page or \n\nmy Google Scholar page.","type":"content","url":"/about#what-i-do","position":3},{"hierarchy":{"lvl1":"About me","lvl2":"About this website"},"type":"lvl2","url":"/about#about-this-website","position":4},{"hierarchy":{"lvl1":"About me","lvl2":"About this website"},"content":"This website is my fork of \n\nChris Holdgraf’s experiment in hosting a personal website and blog via Sphinx extensions instead of using Jekyll. All credit for the website should go to him.","type":"content","url":"/about#about-this-website","position":5},{"hierarchy":{"lvl1":"About me","lvl2":"A rough timeline"},"type":"lvl2","url":"/about#about-timeline","position":6},{"hierarchy":{"lvl1":"About me","lvl2":"A rough timeline"},"content":"Below is a rough timeline of my working life so far.\n\n2025- : Engineer at Earthmover\n\n...\n\n2023-2025: Staff Scientist at [C]Worthy\n\n...\n\n2021-2023: Oceanographer at Columbia University\n\n...\n\n2017: First contributions to Xarray\n\n...\n\n2016-2021: PhD at Culham Centre for Fusion Energy\n\nMy scientific training began ...\n\n2012-2016 Studied Physics at Oxford\n\nGraduated from Oxford University with an MPhys in Physics, specializing in Theoretical and Condensed Matter Physics.","type":"content","url":"/about#about-timeline","position":7},{"hierarchy":{"lvl1":"Blog"},"type":"lvl1","url":"/blog","position":0},{"hierarchy":{"lvl1":"Blog"},"content":"Below are a few of the latest posts in my blog.\nYou can see a full list by year to the left.\n\nScience needs a social network for sharing big data\n\n\n\n\nTom Nicholas, 18th Jan 2025\n\n**Context:** This post was originally published just as a [HackMD doc](https://hackmd.io/@TomNicholas/H1KzoYrPJe). \nOn the back of that post I gave to give a talk & hosted a discussion about this at the [Pangeo Showcase](https://discourse.pangeo.io/t/pangeo-showcase-frost-federated-registry-of-scientific-things-feb-12-2025/4861) ([recording here](https://youtu.be/GZvJ0H89G0A)). If you are interested in helping build the thing please [fill\n\nDate: January 18, 2025 | Author: Tom Nicholas\n\nXarray x NASA: xarray.DataTree for hierarchical data structures\n\n\n\n(Originally posted on the [Xarray blog](https://xarray.dev/blog/datatree).)\n\n\n[`xarray.DataTree`](https://docs.xarray.dev/en/stable/user-guide/data-structures.html#datatree) has been [released](https://github.com/pydata/xarray/discussions/9680) in [v2024.10.0](https://github.com/pydata/xarray/releases/tag/v2024.10.0), and the prototype [`xarray-contrib/datatree` repository](https://github.com/xarray-contrib/datatree) archived, after collaboration between the xarray team and the [NASA ESDIS project](https://www.earthdata.nasa.gov/about/esdis). 🤝\n\n\nThe DataTree concept allows for organizing heterogeneous collections of scientific data in the same way that a nested directory structure facilitates organizing\n\nDate: December 19, 2024 | Author: Tom Nicholas","type":"content","url":"/blog","position":1},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures"},"type":"lvl1","url":"/blog/2024/datatree","position":0},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures"},"content":"(Originally posted on the \n\nXarray blog.)","type":"content","url":"/blog/2024/datatree","position":1},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"tl;dr"},"type":"lvl2","url":"/blog/2024/datatree#tl-dr","position":2},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"tl;dr"},"content":"xarray.DataTree has been \n\nreleased in \n\nv2024.10.0, and the prototype \n\nxarray-contrib/datatree repository archived, after collaboration between the xarray team and the \n\nNASA ESDIS project. 🤝","type":"content","url":"/blog/2024/datatree#tl-dr","position":3},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"Why trees?"},"type":"lvl2","url":"/blog/2024/datatree#why-trees","position":4},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"Why trees?"},"content":"The DataTree concept allows for organizing heterogeneous collections of scientific data in the same way that a nested directory structure facilitates organizing large numbers of files on disk. It does so in a way that preserves common structure between data in the collections, such as aligned arrays and common coordinates.\n\nFor those familiar with netCDF4/Zarr groups, a DataTree can also be thought of as an in-memory representation of a file’s group structure. Xarray users have been \n\nasking for a way to handle multiple netCDF4 groups \n\nsince at least 2016!\n\nDataTree enables xarray to be used for various new use cases, including:\n\nClimate model intercomparisons,\n\nMulti-scale image pyramids, e.g. in \n\ngenomics,\n\nOrganising heterogenous data, such as satellite observations and model simulations.\n\nSimple and convenient access to entire hierarchical files.","type":"content","url":"/blog/2024/datatree#why-trees","position":5},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"What is a DataTree exactly?"},"type":"lvl2","url":"/blog/2024/datatree#what-is-a-datatree-exactly","position":6},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"What is a DataTree exactly?"},"content":"The new high-level container class xarray.DataTree acts like a tree of linked xarray.Dataset objects, with alignment enforced between arrays in parent and child nodes, but not between those in sibling nodes. It can be written to and opened from formats containing multiple groups, such as netCDF4 files and Zarr stores.\n\nFor more details please see the \n\nhigh-level description, the \n\ndedicated page on hierarchical data, and the \n\nsection on IO with groups in the xarray documentation.","type":"content","url":"/blog/2024/datatree#what-is-a-datatree-exactly","position":7},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"Deprecation"},"type":"lvl2","url":"/blog/2024/datatree#deprecation","position":8},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"Deprecation"},"content":"If you previously had used the datatree.DataTree prototype in the \n\nxarray-contrib/datatree repository, that has now been archived and will no longer be supported. Instead we encourage you to migrate to the implementation of DataTree that you can import from xarray, following the \n\nmigration guide.","type":"content","url":"/blog/2024/datatree#deprecation","position":9},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"Big moves"},"type":"lvl2","url":"/blog/2024/datatree#big-moves","position":10},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"Big moves"},"content":"This was a big feature addition! For a \n\ndecade there have been 3 core public xarray data structures, now there are 4: \n\nVariable, \n\nDataArray, \n\nDataset, and now \n\nDataTree.\n\nDatatree represents arguably one of the largest new features added to xarray in 10 years - the migration of the existing prototype alone added >10k lines of code across \n\n80 pull requests, and the resulting datatree implementation now contains contributions from at least 25 people.\n\nWe also had to resolve some really \n\ngnarly design questions to make it work in a way we were happy with.","type":"content","url":"/blog/2024/datatree#big-moves","position":11},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"How did this happen?"},"type":"lvl2","url":"/blog/2024/datatree#how-did-this-happen","position":12},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"How did this happen?"},"content":"DataTree didn’t get implemented overnight - it was a multi-year effort that took place in a number of steps, and there are some lessons to be learned from the story.\n\nIn March 2021, the xarray team submitted a \n\nfunding proposal to the \n\nChan-Zuckerberg Initiative to develop “TreeDataset”, citing bioscience use cases such as \n\nmicroscopy image pyramids. Unfortunately whilst we’ve been lucky to \n\nreceive CZI funding before, on this occasion we didn’t win money to work on the datatree idea.\n\nIn the absence of dedicated funding for datatree, Tom then used some time whilst at the \n\nClimate Data Science Lab at Columbia University to take a initial stab at the design in August 2021 - writing the first implementation on an overnight Amtrak! This simple prototype was released as a separate package in the \n\nxarray-contrib/datatree repository, and steadily gained a small community of intrepid users. It was driven partly by the use case of \n\nclimate model intercomparison datasets.\n\nA separate repository was chosen for speed of iteration, and to be able to more easily \n\nmake changes without worrying as much about \n\nbackwards compatibility as code in xarray’s main repo does. However the separate repo meant that the prototype datatree library was not fully integrated with xarray’s main codebase, limiting possible features and requiring fragile dependencies on private xarray internals.\n\nThe prototype then sat there for 2 years, until the NASA ESDIS team approached the xarray core team in August 2023. ESDIS devs wanted the ability to work with entire hierarchical files, and had experimented with the prototype version of datatree, but they wanted datatree functionality to be migrated upstream into xarray’s main repository so there would be more guarantees of long-term API stability and support.\n\nAmazingly NASA were able to offer the time of 3 engineers: Owen (NASA EOSDIS Evolution and Development 3 (EED-3) contract), Matt (NASA National Snow and Ice Data Center Distributed Active Archive Center (NSIDC)), and Eni (Goddard Earth Sciences Data and Information Services Center (GES DISC)). So starting in late 2023 the NASA trio worked on migrating the prototype datatree into xarray upstream, with regular supervision from Tom, Justus, and Stephan (existing xarray core team).\n\nThis second stage of development allowed us to reduce the bus factor on the datatree code, sanity check the original approach, and it gave us a chance to make some significant improvements to the design without backwards-compatibility concerns (for example enabling the \n\nnew “coordinate inheritance” feature).","type":"content","url":"/blog/2024/datatree#how-did-this-happen","position":13},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"Lessons for future collaborations"},"type":"lvl2","url":"/blog/2024/datatree#lessons-for-future-collaborations","position":14},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"Lessons for future collaborations"},"content":"This development story is different from the more typical scientific grant funding model - how did that work out for us?\n\nThe scientific grant model for funding software expects you to present a full idea in a proposal, wait 6-12 months to hopefully get funding for it, then implement the whole thing during the grant period. In contrast datatree evolved over a gradual process of moving from ideas to hacky prototype to robust implementation, with big time gaps for user feedback and experimentation. The migration was completed by developer-users who actually wanted the feature, rather than grant awardees working in service of a separate and maybe-only-theoretical userbase.\n\nOverall while the migration effort took longer than anticipated we think it worked out quite well!","type":"content","url":"/blog/2024/datatree#lessons-for-future-collaborations","position":15},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl3":"Pros","lvl2":"Lessons for future collaborations"},"type":"lvl3","url":"/blog/2024/datatree#pros","position":16},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl3":"Pros","lvl2":"Lessons for future collaborations"},"content":"Zero overhead - the existing xarray team did not to have to write a proposal to get developer time, and there was literally zero paperwork inflicted (on them at least).\n\nCertainty of funding - writing grant proposals is a lottery, so the time invested up front doesn’t even come with any certainty of funding. Collaborating with another org has a much higher chance of actually leading to more money being available for developer time.\n\nTime efficient - an xarray core dev spending 10% of their time advising someone who is less familiar with the codebase but has more time is an efficient use of relative expertise.\n\nBus factor - the new contributors reduced the bus factor on the datatree code dramatically.\n\nUser-driven Development - it makes sense to have actual interested user communities involved in development.\n\nStakeholder representation - after officially adding Owen, Matt and Eni to the \n\nxarray core team, the NASA ESDIS project has some direct representation in, insider understanding of, and stake in continuing to support the xarray project.","type":"content","url":"/blog/2024/datatree#pros","position":17},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl3":"Cons","lvl2":"Lessons for future collaborations"},"type":"lvl3","url":"/blog/2024/datatree#cons","position":18},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl3":"Cons","lvl2":"Lessons for future collaborations"},"content":"Not everyone got direct funding - It’s less ideal that Tom, Justus, and Stephan didn’t get direct funding for their supervisory work. In future it might be better to have one of the paid people at the contributing org already be a core xarray team member, or perhaps find some way to pay them as a consultant.\n\nTricky to accurately scope - The duration of required work was tricky to estimate in advance, and we didn’t want to “just ship it”. We hold the xarray project to high standards and backwards compatibility promises so we want to ensure that any publicly released features don’t compromise on quality.\n\nThis contributing model is more similar to how open-source software has historically been supported by industry, but perhaps because xarray is primarily developed and used by the scientific community we tend to default to more grant-based funding models.\n\nOverall we think this type of collaboration could work again in future! So if there is an xarray or xarray-adjacent feature your organisation would like to see, please reach out to us.","type":"content","url":"/blog/2024/datatree#cons","position":19},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"Go try out DataTree"},"type":"lvl2","url":"/blog/2024/datatree#go-try-out-datatree","position":20},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"Go try out DataTree"},"content":"Please try datatree out! The hierarchical structure is potentially useful to any xarray users who work with more than one dataset at a time. Simply do from xarray import DataTree or call \n\nopen_datatree(...) on a netCDF4 file / Zarr store containing multiple groups.\n\nBe aware that as xarray.DataTree is still new there will likely be some bugs lurking or places that performance could be improved, as well as as-yet \n\nunimplemented features (as there always are)!","type":"content","url":"/blog/2024/datatree#go-try-out-datatree","position":21},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"Thanks"},"type":"lvl2","url":"/blog/2024/datatree#thanks","position":22},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"Thanks"},"content":"A number of other people also \n\ncontributed to datatree in various ways - particular shoutout to \n\nAlfonso Ladino and \n\nEtienne Schalk for their dedicated attendance at many of the \n\nweekly migration meetings!","type":"content","url":"/blog/2024/datatree#thanks","position":23},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"Funding Acknowledgements"},"type":"lvl2","url":"/blog/2024/datatree#funding-acknowledgements","position":24},{"hierarchy":{"lvl1":"Xarray x NASA: xarray.DataTree for hierarchical data structures","lvl2":"Funding Acknowledgements"},"content":"Owen, Eni, and Matt were able to contribute development time as part of the \n\nNASA ESDIS project.\n\nTom was supported first by the Gordon and Betty Moore foundation as part of Ryan Abernathey’s \n\nClimate Data Science Lab at Columbia University, then later by various funders for a fraction of his time through \n\n[C]Worthy.","type":"content","url":"/blog/2024/datatree#funding-acknowledgements","position":25},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data"},"type":"lvl1","url":"/blog/2025/science-needs-a-social-network","position":0},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data"},"content":"","type":"content","url":"/blog/2025/science-needs-a-social-network","position":1},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl2":"Science needs a social network for sharing big data"},"type":"lvl2","url":"/blog/2025/science-needs-a-social-network#science-needs-a-social-network-for-sharing-big-data","position":2},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl2":"Science needs a social network for sharing big data"},"content":"Tom Nicholas, 18th Jan 2025\n\nContext: This post was originally published just as a \n\nHackMD doc.\nOn the back of that post I gave to give a talk & hosted a discussion about this at the \n\nPangeo Showcase (\n\nrecording here). If you are interested in helping build the thing please \n\nfill out this form!\n\ntl;dr: Science is missing a crucial data sharing network. We have the technology - here’s what we should build.","type":"content","url":"/blog/2025/science-needs-a-social-network#science-needs-a-social-network-for-sharing-big-data","position":3},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"Data sharing sucks","lvl2":"Science needs a social network for sharing big data"},"type":"lvl3","url":"/blog/2025/science-needs-a-social-network#data-sharing-sucks","position":4},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"Data sharing sucks","lvl2":"Science needs a social network for sharing big data"},"content":"Sharing large scientific datasets is a pain in the ass, and finding them is even worse. There are myriad portals and tools and APIs and bucket URLs and crappy catalogs that are split across arbitrary geographic and institutional lines, which are often slow or have gone down, or will only give you part of the data or in a suboptimal pattern or in a format you’ve never heard of. Crucial datasets aren’t easy to find by Googling, and because you don’t know where they live (or even if what you want exists anywhere) you don’t know which institutions’ catalog to comb through. That’s if anyone even bothered to put the data online, rather than just fobbing you off with “available upon request” and a gesture towards an out-of-date email address.\n\nImagine instead simply being able to visit one website, search for any scientific dataset from any institution in the world, preview it, then stream the data out at high speed, in the format you prefer. A true “scientific data commons”.","type":"content","url":"/blog/2025/science-needs-a-social-network#data-sharing-sucks","position":5},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"Scientists love GitHub","lvl2":"Science needs a social network for sharing big data"},"type":"lvl3","url":"/blog/2025/science-needs-a-social-network#scientists-love-github","position":6},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"Scientists love GitHub","lvl2":"Science needs a social network for sharing big data"},"content":"For sharing code, this commons already exists: it’s called \n\nGitHub. “Just put it on GitHub” has become the “Open Science” community’s mantra. As well as being the de facto way to share code underlying individual scientific papers, GitHub has enabled open collaboration on impactful scientific software projects (including true inter-disciplinary collaboration between otherwise unrelated fields). Despite being privately-owned, we regularly champion its use under the \"Open science” banner, as it is an enormous boon for open science worldwide.","type":"content","url":"/blog/2025/science-needs-a-social-network#scientists-love-github","position":7},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"GitHub is a centralized social network","lvl2":"Science needs a social network for sharing big data"},"type":"lvl3","url":"/blog/2025/science-needs-a-social-network#github-is-a-centralized-social-network","position":8},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"GitHub is a centralized social network","lvl2":"Science needs a social network for sharing big data"},"content":"GitHub is a version-controlled code hosting site with easy local backups, but it’s also arguably a social network - upon launch in 2008 their strapline was \n\n“Social Code Hosting”. You can like, comment, subscribe, and follow users, repositories, and organisations.\n\nNote that whilst the source code they host is distributed (via backing up by everyone that clones a repository) their social network is completely centralized. All the issues, comments, followers etc. live in GitHub’s servers, are not automatically backed up by any other organisation, and are only acessible through the GitHub web platform or official API.","type":"content","url":"/blog/2025/science-needs-a-social-network#github-is-a-centralized-social-network","position":9},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"GitHub for data?","lvl2":"Science needs a social network for sharing big data"},"type":"lvl3","url":"/blog/2025/science-needs-a-social-network#github-for-data","position":10},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"GitHub for data?","lvl2":"Science needs a social network for sharing big data"},"content":"Most modern scientific works are really composed of up to 3 artifacts: the manuscript, data, and code. Science is currently often done by disseminating the manuscript alone via a journal, but efficient sharing of all three is necessary to have any hope of reproducibility of scientific results.\n\nManuscript sharing networks exist but are hamstrung by publicly-funded content being brutally paywalled by parasitic for-profit organisations (otherwise known as “Scientific Publishers”). But that shitshow deserves discussion in a separate post.\n\nGitHub is designed specifically for sharing code - using it to share data is really misusing the platform. The fact that people do still share (small) data this way regularly shows there is an unfullfilled need.\n\nWhat we still need is a global social network for sharing big scientific datasets, or a “GitHub for data”.","type":"content","url":"/blog/2025/science-needs-a-social-network#github-for-data","position":11},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"Goal of “FAIR” scientific data","lvl2":"Science needs a social network for sharing big data"},"type":"lvl3","url":"/blog/2025/science-needs-a-social-network#goal-of-fair-scientific-data","position":12},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"Goal of “FAIR” scientific data","lvl2":"Science needs a social network for sharing big data"},"content":"To imagine something new, let’s keep in mind the oft-cited (but rarely achieved) \n\n“FAIR data principles”. These state that scientific data assets should be Findable, Accessible, Interoperable, and Reproducible.","type":"content","url":"/blog/2025/science-needs-a-social-network#goal-of-fair-scientific-data","position":13},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"What would the ideal data-sharing service look like?","lvl2":"Science needs a social network for sharing big data"},"type":"lvl3","url":"/blog/2025/science-needs-a-social-network#what-would-the-ideal-data-sharing-service-look-like","position":14},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"What would the ideal data-sharing service look like?","lvl2":"Science needs a social network for sharing big data"},"content":"The ideal data-sharing service would have a number of important properties:\n\nUnified\n\nA catalog of all scientific data in the world should have global search and connections across all projects, regardless of instutition or academic subfield.\n\nThis feature of GitHub is what allows true interdisciplinary collaboration within \n\nfoundational software projects. Any other approach causes fragmentation and artifical boundaries between hazily-defined fields of science, and wastes effort through re-inventing unnecessarily bespoke solutions for generic data engineering problems.\n\nOpen to anyone\n\nAnyone should be able to create a public catalog entry for their dataset on the platform.\n\nThis doesn’t mean it necessarily has to be free to upload data to the catalog, but it should be possible for anyone who can pay a reasonable hosting fee to do so (like the commercial cloud, dropbox, or website hosting). This means that no institutional login should be required, no requirement for a .edu email address, no requirement to be in a specific country, etc.\n\nFree to browse\n\nAnyone should be able to use the platform to browse and discover public datasets, without them being paywalled.\n\nDownloading the actual data doesn’t need to be free (and shouldn’t be - bandwidth for big data is expensive so downloading it unnecessarily should be disincentivised), but viewing enough metadata to decide if you want to get the actual contents should be free. This is especially important for crucial public data such as real-time satellite imagery of wildfires - which infuriatingly is not necessarily findable \n\neven by experts.\n\nScalable to massive datasets\n\nThe platform should be able to handle the biggest datasets in science.\n\nIn many fields the largest datasets are some of the most important. That’s especially true in physical sciences such as climate science, meteorology, neuroscience, and genomics. For example \n\nERA5 is effectively our best guess as to the Earth’s weather over the last 80 years, and as such it’s the starting point for a huge amount of climate / meteorology / hazard & energy forecasting research. Unfortunately it’s about 5 Peta-Bytes in size, so could only be hosted by a system that can handle arbitrarily large datasets.\n\nAs the \n\nPangeo project in big data geoscience has shown, this can’t be an afterthought, because sharing big data requires fundamentally different architectures (i.e. \n\ncloud-native data repositories). Luckily placing data in S3-compatible public-facing cloud storage also solves the problem of ensuring open accessibility and scalable computing resources for data analysis. Agencies like NASA are already catching on to this whole cloud idea, but not to the full potential that this infrastructure technology enables.\n\nGlobally available\n\nThe same data should be available to anyone in the world.\n\nCloud storage allows large datasets to be available to anyone within a \n\ncloud region, but the technical challenge is guarantee that copies of data stored in different cloud regions are consistent with one another. One approach is to do this at the level of the storage itself (e.g. \n\nTigris), but another is to have automatic methods of \n\nguaranteeing consistency between copies.\n\nCommon data models\n\nThe vast majority of scientific data can be represented via one of 2 or 3 common data models. Particularly Tabular data (rows and columns, think spreadsheets), and Multi-dimensional Array (or “Tensor”) data (grids of values, think latitude-longitude). Many fields of physical science are naturally described via Multi-dimensional Arrays, because the universe we live in is 4-dimensional. For example climate/weather simulations, microscope imagery, but also more abstract dimensions such as DNA base pairs in genomics.\n\nRecognising this (still extremely general) structure allows for plugging in to all the existing tools in the world designed to process, analyse, and visualize data. For example, adopting common tabular data formats allows the use of off-the-shelf \n\ndata processing technologies, so is really required to achieve the FAIR principle of \n\nInteroperability. This idea is so useful that platforms for managing Tabular data specifically for e-commerce businesses are themselves worth \n\nbillions of dollars.\n\nIn the world of Tabular data \n\ncommon models are well-established, and in the world of array data the \n\nZarr model is general enough to abstract over many existing scientific array data formats, often \n\nwithout even altering the original data format.\n\nVersion-controlled\n\nThe key value-add of git is the way it tracks every change to your source code. A robust version control system is crucial to have any hope of reproducibility, and that’s true also for data. Luckily open-source systems such as \n\nApache Iceberg (Tabular) and \n\nEarthmover’s recent release of \n\nIcechunk (Arrays) both allow users to rollback to old versions of data to reproduce results.\n\nWithout this crucial building block previous attempts to create an updateable version-controlled catalog have often become mired in all the complexity needed to make up for the lack of intrinsically version-controlled data models.\n\nData ownership\n\nUsing the platform should not require you to relinquish legal or technical control over your data. (This is how the the scientific publishing industry really screwed us all over.)\n\nThis requires openly-licensed data formats (which Iceberg and Icechunk both are), as well as the option for data to reside on your own infrastructure. The platform then merely catalogs references to data that actually still lives on other systems. The cloud works well for this - data can live in one bucket but be referenced from anywhere, and data consumers don’t necessarily have to know the difference.\n\nCitable dependency networks\n\nDatasets in the catalog should be citable, and it should be possible to see which datasets are derived from which others.\n\nThe \n\nDOI system makes this technically pretty straightforward, but it’s sociologically crucial for scientists to be able gain career credit for non-manuscript contributions (such as widely-used datasets and open-source code). The fact this kind of credit currently is both difficult to obtain and undervalued by tenure committees is a major source of misaligned career incentives in science.\n\nSubscribable\n\nMany scientific datasets are not just derived from upstream data, they should actually be updated every time the upstream data is updated.\n\nA \n\nPublisher-Subscriber model (think RSS blog feeds) would allow recomputing derived data upon updates to upstream data. For example, imagine recomputing a metric of wildfire risk whenever new satellite imagery becomes available.\n\nSocial\n\nScience progresses through debate, and so the data catalog should include spaces for debate.\n\nThis could take the form of public comments, or GitHub-like issue raising. Version-control also theoretically allows public submission of data corrections (i.e. Pull Requests that update data). Whilst this brings up the spectre of Moderation, at least moderation here would be federated in that each data project’s owners would have the power and incentive to moderate their own space. This approach scales with the number of datasets, and seems to work relatively well for GitHub.\n\nScientists also have professional social networks, and users being able to follow specific scientists, datasets, or data providers would simply formalize and streamline data-sharing networks which already exist informally.\n\nSustainably-fundable\n\nSomething of this scope would cost someone \n\nmillions of dollars every year to build and maintain. Ideally the project would generate this funding itself.\n\nThere’s no way around that figure - it requires hosting infrastructure (servers) and staff (expensive software engineers) - decentralizing the project would just split the same cost among more institutions. If you want it to actually work anywhere near as well as GitHub it would cost even more than that, to pay for expensive industry-grade UX designers and site reliability engineers and so on.\n\nThe funding mechanism also needs to scale up proportionally to the size of the user base - and it’s important that the project is actually incentivised to provide a good service. GitHub handles these problems by being a private company offering a useful service to businesses, with a free tier for public repositories but a paid tier for private ones.\n\nRight to Exit\n\nIt’s important that a global network of scientific knowledge is not beholden to any one institution or company. However it would be hard to build the unified search and dependency/social network features, use common data models, and get economies of scale without some degree of centralization.\n\nThis is a similar problem to social media: users want to be on the same network, accessed via a platform with a high-quality interface. But they also want to be able to leave without losing their personal/professional network if there is an \n\n“Elon Musk Event” threatening trust in the platform. For social networks this \n\n“Right of Exit” is harder to achieve than simply having multiple platform vendors or open data formats, because an alternative service doesn’t automatically come with \n\nyour follower network on it.\n\nOne idea for avoiding being locked-in to a social network is decentralization. Mastodon and Bluesky both claim to be decentralized in a way that safeguards your Right to Exit. Their solution is to separate the network from the platform used to interact with the network, and make the network layer an open protocol. Think of email: while no-one owns the “email network”, there are many platforms you can use to send and receive emails (Outlook, GMail, Thunderbird etc.), and you can switch between them. This is possible because there is a public email protocol which every email provider uses to send messages between them.\n\nDecentralizing an entire social network turns out to be \n\nincredibly challenging. A more tractable idea that could still help alleviate lock-in would be a decentralized catalog protocol. That would at least allow multiple institutions / other companies to host their own data catalogs, and have them integrate fully, with shared global search and dependency networks. To be more concrete, imagine NASA hosts a catalog of Icechunk repositories on the platform IceHub, whilst NOAA hosts some others on a different platform IceBucket. A shared decentralized network using a public protocol would allow the NASA data repositories to subscribe to updates from the NOAA datasets, with bi-directional linking, despite being on different platforms. It would also allow either platform to easily provide a search index that covers all public datasets on both platforms. One naive way to do this is would be to simply have the full public network be stored on both platform’s servers (somewhat like \n\nNNTP), which also means that if IceHub disappeared then IceBucket could expand to serve the same institutions without losing the record of the dataset dependency network.\n\nA major high-quality platform can still exist - this just allows other platforms to potentially also exist, whilst being connected to the same network. Such decentralization combined with open data formats and data ownership should allow the development of such a high-quality platform whilst minimizing risk of data or network lock-in. It would also aid the switch to whatever future scientific infrastructure we realise we need after this platform, assuming we’re all still around by then.\n\nTo be clear, of all the requirements, this last one is the only one that I’m not actually sure is even technically possible. It would be \n\nawesome though, so I would love it if someone who knows more than I about networking protocols could weigh in. \n\nHere’s a place for brainstorming ideas.","type":"content","url":"/blog/2025/science-needs-a-social-network#what-would-the-ideal-data-sharing-service-look-like","position":15},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"Surely this exists already?","lvl2":"Science needs a social network for sharing big data"},"type":"lvl3","url":"/blog/2025/science-needs-a-social-network#surely-this-exists-already","position":16},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"Surely this exists already?","lvl2":"Science needs a social network for sharing big data"},"content":"Whilst various initiatives (federal, non-profit, and for-profit) aim to solve some of these problems, as far as I am aware nothing currently exists which meets all of the criteria above simultaneously. Let’s briefly discuss where major existing efforts fall short.\n\nNot even trying - the vast majority of scientific data is only available “upon request”, which is to say, not openly available at all. Given that this data was created with public money, and the public would benefit from it being openly accessible, this is unacceptable.\n\nRolling-their-own catalogs and data portals is currently most large institutions’ approach (e.g. \n\n[1] \n\n[2] \n\n[3] \n\n[4] \n\n[5] \n\n[6]), if they bother with a unified data catalog at all. This leads to massive waste through duplication of effort and difficulty finding relevant data outside of that one institution, only to end up with a mess of services which don’t generalize, interoperate, or even necessarily work very well. These existing services also are not open to anyone - they very much care \n\nwho you are - which limits the practice of data-driven science to a \n\nsubset of society. Worse, many institutions such as universities and national labs actively make it harder to access data instead of easier, by requiring strict affiliation and access controls to be permitted behind the walls of their “data fortress”, then making it very hard to free the data even once you have access.\n\nSTAC, which stands for Spatio-Temporal Asset Catalog, is an open specification providing a common structure for describing and cataloging geospatial datasets. STAC is extremely cool, but it isn’t quite what we need. Firstly, the data model is not general enough - it’s intimately tied to \n\ngeospatial-specific concepts. There is plenty of scientific data that is multidimensional arrays but nothing to do with the earth’s surface, e.g. \n\nstatistical genetics data and \n\nmicroscope imaging data. Secondly, because STAC’s core is a static catalog and API specification, not a network protocol, it’s not designed to faciliate dynamic updates or global connectivity. (This is different to STAC’s idea of a \n\n“Dynamic Catalog”, which is better understood as a static catalog created on-demand.) Some groups have built tooling on top to provide a \n\nunified STAC catalog, a \n\nsearchable index and \n\npublish update notifications, but they must step outside the STAC specification to do so and hence lose some of the decentralization. Nevertheless this is all great inspiration, and a general cataloging protocol should play nicely with STAC in an extensible way, as the core spec is a perfect example of the domain-specific metadata conventions that each field of science should organize amongst themselves.\n\nIntake is another open-source data catalog project from within the scientific python ecosystem. An Intake Catalog is in theory a little bit like a STAC catalog, but more general. Unfortunately Intake also tries to solve several other problems at the same time, including data loading, transformation, and processing. The result is that the \n\ncatalog definitions are python-specific, and hence not interoperable.\n\nZenodo and \n\nDataverse are science-oriented hosting services. Whilst great initiatives, they aren’t designed to share big data or to exploit common scientific data models. For example Zenodo has a max dataset size of 50GB, whilst crucial climate science datasets can be many PetaBytes in size - at least 5 orders of magnitude larger! A service which doesn’t take advantage of the fact that the vast majority of scientific data is either multidimensional arrays or tabular (i.e. they treat all data as unstructured) from a user perspective is not really that different from just putting raw binary files into GitHub - i.e. the repository doesn’t understand that your data has any useful common structure. The funding model of these services also appears to be entirely based on public grants. (I must say Dataverse is pretty impressive, and perhaps the closest existing design I’ve seen to being capable of hitting all the technical requirements on this list.)\n\nGitHub being mis-used as a file sharing service does fulfil several of these properties, including being sustainably-funded. But again it’s not Scalable nor does it use Common Data Models, and it can’t really be made so (because GitHub and git itself were designed for something completely different: handling small text files containing source code). It’s also not decentralized - whilst \n\nGitHub’s package dependency graph is publicly available, it arguably does not fulfil the “Credible Exit” criteria according to BlueSky’s definition, because you cannot simply switch over to another provider like GitLab whilst retaining your network connections.\n\nWikipedia is another existing example of a commons, a knowledge commons. It is fully open-source, unified, open, federated, and sustainably-funded. It also hosts data through \n\nWikiData, so could we just put our scientific data there? Unfortunately whilst the size of the work to create and maintain Wikipedia is incredible, the actual amount of data stored is smaller than you might think. Once compressed, the size of all the English text on Wikipedia is a miniscule \n\n24 GB! Even downloading all the images and so on only requires \n\nabout 25TB - that fits on one big external hard drive. Again this is not the required scale of data hosting, which would require a completely different architecture (i.e. a cloud-native one). Also note that the majority of funding comes from \n\nindividual public donations (I donate - you should too). That’s awesome, but doesn’t seem like an approach that would work for a scientific data platform invisible to most of the public.\n\nSnowflake is a commercial product: a proprietary cloud data platform that’s widely used by the private sector. It’s extremely scalable as it’s designed for big (business) data, and sustainably-funded in the sense of being very profitable. However it doesn’t recognise anything other than Tabular data, because almost all business data is Tabular. A platform set up to manage companies’ private data also has little need for a public global data catalog, as unlike scientists, businesses don’t tend to openly share data with one another.\n\nHugging Face Hub is another platform from another private company, but for sharing Machine Learning training datasets and model weights. It works well for that community, but again it is not truly Scalable (because your data has to be uploaded to \n\ntheir storage) nor does it use a Common Data Model (though \n\nit could), and is ML-specific. \n\nDagsHub is very similar, except that it lets you connect your own storage bucket, and has version-control. However, the version-control system assumes unstructured data. It’s also worth noting that the stupid amounts of money being poured into the ML sphere incentivises the founding of multiple companies trying to provide data-sharing services, whereas in science there are far fewer, even though there is no fundamental difference between ML “tensor” model weights and scientific multidimensional array data.\n\nSource Cooperative is a non-profit data-sharing utility that basically wraps cloud storage buckets provided by the \n\nAWS Open data program, so is Free to Browse and Scalable to large datasets. In theory Source could evolve to meet many of the criteria above, but note that one big missing requirement that would be hard to add later is Common Data Models - Source is essentially just a catalog of buckets, each full of potentially inconsistent and unrelated objects. For now it’s still in beta, so has few features, is effectively invite-only, and does not yet have a clear sustainable funding mechanism in place.\n\nGoogle Earth Engine is scalable, and does understand the raster data model (2D arrays of geospatial imagery). However, it’s geoscience-specific, doesn’t respect Data Ownership and is completely Centralized - as all the data lives on Google machines. Crucially it’s also not sustainably-funded - Google runs it at a loss, and have only recently started trying to monetize it. Nevertheless Earth Engine is widely used, meaning that an alarming number of environmental non-profits completely depend on the charity of a big corporation, who have no obvious reason beyond PR to keep funding the service for free, and could \n\npull the plug at literally any time.\n\nEDIT: Every time I show someone new this post they suggest another hosting service that I hadn’t heard of. So far none of them meet all the 13 criteria above, and most of them fall down on Scalability or Common data models.","type":"content","url":"/blog/2025/science-needs-a-social-network#surely-this-exists-already","position":17},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"Conclusion","lvl2":"Science needs a social network for sharing big data"},"type":"lvl3","url":"/blog/2025/science-needs-a-social-network#conclusion","position":18},{"hierarchy":{"lvl1":"Science needs a social network for sharing big data","lvl3":"Conclusion","lvl2":"Science needs a social network for sharing big data"},"content":"There’s a major missing link in the way the world shares scientific data. Until we build it we cannot reasonably expect results from data-intensive science to be truly Findable, Accessible, Interoperable, or Reproducible. Though still a major effort, luckily cloud computing and recent advances in key open-source software libraries bring the idea within reach.","type":"content","url":"/blog/2025/science-needs-a-social-network#conclusion","position":19},{"hierarchy":{"lvl1":"Hi, I’m Tom Nicholas 👋"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Hi, I’m Tom Nicholas 👋"},"content":"\n\nA bit about me...\n\n💼 Engineer @ \n\nEarthmover\n\n🌎 Active member of the \n\nPangeo Community\n\n🌕 Core developer of \n\nXarray\n\n🧪 PhD in fusion plasma physics from \n\nUni. York & \n\nCCFE\n\nI also work on several other \n\nopen-source projects for science.\n\nAbout me ℹ️ :::{grid-item-card}\n:link: projects.md\nProjects I've worked on 🔧\n::: \n\nMy blog ✍️","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Hi, I’m Tom Nicholas 👋","lvl2":"Recent blog posts"},"type":"lvl2","url":"/#recent-blog-posts","position":2},{"hierarchy":{"lvl1":"Hi, I’m Tom Nicholas 👋","lvl2":"Recent blog posts"},"content":"Science needs a social network for sharing big data\n\n\n\n\nTom Nicholas, 18th Jan 2025\n\n**Context:** This post was originally published just as a [HackMD doc](https://hackmd.io/@TomNicholas/H1KzoYrPJe). \nOn the back of that post I gave to give a talk & hosted a discussion about this at the [Pangeo Showcase](https://discourse.pangeo.io/t/pangeo-showcase-frost-federated-registry-of-scientific-things-feb-12-2025/4861) ([recording here](https://youtu.be/GZvJ0H89G0A)). If you are interested in helping build the thing please [fill\n\nDate: January 18, 2025 | Author: Tom Nicholas\n\nXarray x NASA: xarray.DataTree for hierarchical data structures\n\n\n\n(Originally posted on the [Xarray blog](https://xarray.dev/blog/datatree).)\n\n\n[`xarray.DataTree`](https://docs.xarray.dev/en/stable/user-guide/data-structures.html#datatree) has been [released](https://github.com/pydata/xarray/discussions/9680) in [v2024.10.0](https://github.com/pydata/xarray/releases/tag/v2024.10.0), and the prototype [`xarray-contrib/datatree` repository](https://github.com/xarray-contrib/datatree) archived, after collaboration between the xarray team and the [NASA ESDIS project](https://www.earthdata.nasa.gov/about/esdis). 🤝\n\n\nThe DataTree concept allows for organizing heterogeneous collections of scientific data in the same way that a nested directory structure facilitates organizing\n\nDate: December 19, 2024 | Author: Tom Nicholas","type":"content","url":"/#recent-blog-posts","position":3}]}